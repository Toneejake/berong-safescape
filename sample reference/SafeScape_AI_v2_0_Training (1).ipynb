{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Tl7zgsS3-tD"
      },
      "source": [
        "#  Cell 1: Installations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zd6ZGIZGKIEi",
        "outputId": "281c911b-c8fd-44f4-fbae-e3eba76a062c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/93.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.2/93.2 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/187.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m187.2/187.2 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# Cell 1: Installations\n",
        "# Install PyTorch with CUDA support\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118 -q\n",
        "# Install core libraries for simulation, data, and AI\n",
        "!pip install datasets Pillow matplotlib scikit-learn gymnasium opencv-python-headless -q\n",
        "# Install the Stable Baselines3 libraries for Reinforcement Learning\n",
        "!pip install stable-baselines3[extra] sb3-contrib -q"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-ocJSPP4C5J"
      },
      "source": [
        "# Cell 2: Imports and Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sN8bNNAlr6E6",
        "outputId": "b5445c5c-0150-4fcb-8fe0-7809aa8749cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Configuration Loaded ---\n",
            "Using device: cuda\n",
            "Max Agents: 10, Max Exits: 248\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Gym has been unmaintained since 2022 and does not support NumPy 2.0 amongst other critical functionality.\n",
            "Please upgrade to Gymnasium, the maintained drop-in replacement of Gym, or contact the authors of your software and request that they upgrade.\n",
            "See the migration guide at https://gymnasium.farama.org/introduction/migration_guide/ for additional information.\n",
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n"
          ]
        }
      ],
      "source": [
        "# Cell 2: Imports and Global Configuration\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import gymnasium as gym\n",
        "from gymnasium import spaces\n",
        "import heapq\n",
        "import cv2\n",
        "import os\n",
        "import random\n",
        "\n",
        "# Stable Baselines 3 and extensions\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.env_util import make_vec_env\n",
        "from stable_baselines3.common.vec_env import SubprocVecEnv\n",
        "from sb3_contrib import MaskablePPO\n",
        "from sb3_contrib.common.wrappers import ActionMasker\n",
        "\n",
        "# --- Global Configuration for the V2.0 Model ---\n",
        "config = {\n",
        "    # --- Simulation Parameters ---\n",
        "    \"MAX_AGENTS\": 10,         # The fixed number of agent \"slots\" for the observation\n",
        "    \"MAX_EXITS\": 248,         # The fixed number of perimeter \"exit slots\" for the action mask\n",
        "    \"GRID_SIZE\": 64,          # The fixed size of the grid the AI will \"see\"\n",
        "\n",
        "    # --- Agent Behavior ---\n",
        "    \"PANIC_DISTANCE\": 20,     # Reduced distance to make panic more likely\n",
        "    \"ALERT_DISTANCE\": 40,\n",
        "\n",
        "    # --- Training Parameters ---\n",
        "    \"TOTAL_TIMESTEPS\": 1_000_000, # Target for the full training run (can be done in chunks)\n",
        "    \"N_ENVS\": 8,              # Number of parallel environments (good for T4 GPU)\n",
        "    \"BATCH_SIZE\": 256,\n",
        "\n",
        "    # --- File Paths ---\n",
        "    \"UNET_MODEL_PATH\": \"unet_floorplan_model.pth\",\n",
        "    \"PPO_MODEL_PATH\": \"ppo_commander_v2.0.zip\",\n",
        "\n",
        "    # --- Dataset ---\n",
        "    \"DATASET_NAME\": \"zimhe/pseudo-floor-plan-12k\"\n",
        "}\n",
        "\n",
        "# --- Device Configuration ---\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "print(\"--- Configuration Loaded ---\")\n",
        "print(f\"Using device: {device}\")\n",
        "print(f\"Max Agents: {config['MAX_AGENTS']}, Max Exits: {config['MAX_EXITS']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Id7QruFF4FFd"
      },
      "source": [
        "# Cell 3: Load Pre-Trained U-Net and Define Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jNw5G2jMKaX3",
        "outputId": "e1a8299f-27f7-4a2d-d06e-c33b85145eec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- U-Net model loaded successfully ---\n",
            "Helper function 'create_grid_from_image' is defined.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# 1. Re-define the U-Net Model Architecture\n",
        "# This must be the EXACT same structure as the one we used for training in the previous notebook.\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(UNet, self).__init__()\n",
        "        def double_conv(in_channels, out_channels):\n",
        "            return nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
        "                nn.ReLU(inplace=True))\n",
        "        self.dconv_down1 = double_conv(3, 64)\n",
        "        self.dconv_down2 = double_conv(64, 128)\n",
        "        self.dconv_down3 = double_conv(128, 256)\n",
        "        self.dconv_down4 = double_conv(256, 512)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.dconv_up3 = double_conv(256 + 512, 256)\n",
        "        self.dconv_up2 = double_conv(128 + 256, 128)\n",
        "        self.dconv_up1 = double_conv(128 + 64, 64)\n",
        "        self.conv_last = nn.Conv2d(64, 1, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        conv1 = self.dconv_down1(x); x = self.maxpool(conv1)\n",
        "        conv2 = self.dconv_down2(x); x = self.maxpool(conv2)\n",
        "        conv3 = self.dconv_down3(x); x = self.maxpool(conv3)\n",
        "        x = self.dconv_down4(x)\n",
        "        x = nn.functional.interpolate(x, scale_factor=2, mode='bilinear', align_corners=True)\n",
        "        x = torch.cat([x, conv3], dim=1); x = self.dconv_up3(x)\n",
        "        x = nn.functional.interpolate(x, scale_factor=2, mode='bilinear', align_corners=True)\n",
        "        x = torch.cat([x, conv2], dim=1); x = self.dconv_up2(x)\n",
        "        x = nn.functional.interpolate(x, scale_factor=2, mode='bilinear', align_corners=True)\n",
        "        x = torch.cat([x, conv1], dim=1); x = self.dconv_up1(x)\n",
        "        return self.conv_last(x)\n",
        "\n",
        "# 2. Load the trained U-Net weights from the file\n",
        "unet_model = UNet().to(device)\n",
        "try:\n",
        "    unet_model.load_state_dict(torch.load(config[\"UNET_MODEL_PATH\"], map_location=device))\n",
        "    unet_model.eval()  # Set the model to evaluation mode (very important!)\n",
        "    print(\"--- U-Net model loaded successfully ---\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"--- ERROR: U-Net model file not found at '{config['UNET_MODEL_PATH']}' ---\")\n",
        "    print(\"Please make sure you have uploaded the .pth file to the Colab session.\")\n",
        "\n",
        "# 3. Define the image processing helper function\n",
        "def create_grid_from_image(unet_model, pil_image):\n",
        "    \"\"\"\n",
        "    Takes a loaded U-Net model and a PIL Image object,\n",
        "    and returns a binary numpy grid resized to the simulation GRID_SIZE.\n",
        "    \"\"\"\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((config['GRID_SIZE'], config['GRID_SIZE'])),\n",
        "        transforms.ToTensor(),\n",
        "    ])\n",
        "\n",
        "    input_tensor = transform(pil_image).unsqueeze(0).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = unet_model(input_tensor)\n",
        "\n",
        "    output_probs = torch.sigmoid(output)\n",
        "    binary_mask = (output_probs > 0.5).float()\n",
        "\n",
        "    grid_numpy = binary_mask.squeeze().cpu().numpy()\n",
        "    return grid_numpy\n",
        "\n",
        "print(\"Helper function 'create_grid_from_image' is defined.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8mUEo6o4TeS"
      },
      "source": [
        "# Cell 4: Upgraded Simulation Classes (Person, Fire, and the new EvacuationEnv)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rV_M_C7cKaIw",
        "outputId": "98ca9816-dcd0-465f-d8c1-82d95ce28149"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Upgraded Simulation Classes Defined ---\n",
            "EvacuationEnv is now ready for Action Masking and Padded Observations.\n"
          ]
        }
      ],
      "source": [
        "# --- A* Pathfinding (Unchanged) ---\n",
        "def a_star_search(grid, start, goal, fire_map=None):\n",
        "    def heuristic(a, b): return abs(a[0] - b[0]) + abs(a[1] - b[1])\n",
        "    neighbors = [(0, 1), (0, -1), (1, 0), (-1, 0)]\n",
        "    close_set, came_from, gscore = set(), {}, {start: 0}\n",
        "    fscore = {start: heuristic(start, goal)}\n",
        "    oheap = [(fscore[start], start)]\n",
        "    while oheap:\n",
        "        current = heapq.heappop(oheap)[1]\n",
        "        if current == goal:\n",
        "            path = []\n",
        "            while current in came_from: path.append(current); current = came_from[current]\n",
        "            return path[::-1]\n",
        "        close_set.add(current)\n",
        "        for i, j in neighbors:\n",
        "            neighbor = current[0] + i, current[1] + j\n",
        "            if not (0 <= neighbor[0] < grid.shape[1] and 0 <= neighbor[1] < grid.shape[0]): continue\n",
        "            if grid[neighbor[1]][neighbor[0]] == 1: continue\n",
        "            if fire_map is not None and fire_map[neighbor[1]][neighbor[0]] == 1: continue\n",
        "\n",
        "            tentative_g_score = gscore[current] + 1\n",
        "            if neighbor in close_set and tentative_g_score >= gscore.get(neighbor, 0): continue\n",
        "            if tentative_g_score < gscore.get(neighbor, 0) or neighbor not in [i[1] for i in oheap]:\n",
        "                came_from[neighbor], gscore[neighbor] = current, tentative_g_score\n",
        "                fscore[neighbor] = tentative_g_score + heuristic(neighbor, goal)\n",
        "                heapq.heappush(oheap, (fscore[neighbor], neighbor))\n",
        "    return []\n",
        "\n",
        "# --- Person and FireSimulator Classes (Unchanged from our last version) ---\n",
        "class Person:\n",
        "    def __init__(self, position):\n",
        "        self.initial_pos, self.pos = tuple(position), list(position)\n",
        "        self.path, self.status = [], 'evacuating'\n",
        "        self.state, self.speed, self.trip_probability, self.tripped_timer = 'CALM', 1.0, 0.0, 0\n",
        "    def update_state(self, fire_map):\n",
        "        if self.tripped_timer > 0: return\n",
        "        fire_locs = np.argwhere(fire_map == 1)\n",
        "        min_dist = np.min(np.linalg.norm(fire_locs - np.array([self.pos[1], self.pos[0]]), axis=1)) if len(fire_locs) > 0 else float('inf')\n",
        "        if min_dist < config[\"PANIC_DISTANCE\"]: self.state, self.speed, self.trip_probability = 'PANICKED', 1.5, 0.1\n",
        "        elif min_dist < config[\"ALERT_DISTANCE\"]: self.state, self.speed, self.trip_probability = 'ALERT', 1.2, 0.0\n",
        "        else: self.state, self.speed, self.trip_probability = 'CALM', 1.0, 0.0\n",
        "    def move(self):\n",
        "        if self.tripped_timer > 0: self.tripped_timer -= 1; return\n",
        "        if self.state == 'PANICKED' and np.random.rand() < self.trip_probability: self.tripped_timer = 5; return\n",
        "        for _ in range(int(round(self.speed))):\n",
        "            if self.path: self.pos = self.path.pop(0)\n",
        "            else: break\n",
        "    def check_status(self, fire_map, exits):\n",
        "        if self.status != 'evacuating': return\n",
        "        pos_yx = (int(self.pos[1]), int(self.pos[0]))\n",
        "        if fire_map[pos_yx[0], pos_yx[1]] == 1: self.status = 'burned'; return\n",
        "        if any(np.linalg.norm(np.array(self.pos) - np.array(ex)) < 5 for ex in exits): self.status = 'escaped'\n",
        "    def compute_path(self, grid, goal, fire_map):\n",
        "        self.path = a_star_search(grid, (int(self.pos[0]), int(self.pos[1])), (int(goal[0]), int(goal[1])), fire_map)\n",
        "    def reset(self):\n",
        "        self.pos = list(self.initial_pos); self.path = []; self.status = 'evacuating'\n",
        "        self.state, self.speed, self.trip_probability, self.tripped_timer = 'CALM', 1.0, 0.0, 0\n",
        "\n",
        "class FireSimulator:\n",
        "    def __init__(self, grid, spread_prob=0.25): self.grid, self.spread_prob = grid, spread_prob; self.reset()\n",
        "    def step(self):\n",
        "        new_fire = self.fire_map.copy()\n",
        "        for y, x in np.argwhere(self.fire_map == 1):\n",
        "            for dy, dx in [(0,1), (0,-1), (1,0), (-1,0)]:\n",
        "                ny, nx = y + dy, x + dx\n",
        "                if 0 <= ny < self.grid.shape[0] and 0 <= nx < self.grid.shape[1] and self.fire_map[ny, nx] == 0 and self.grid[ny, nx] == 0 and np.random.rand() < self.spread_prob:\n",
        "                    new_fire[ny, nx] = 1\n",
        "        self.fire_map = new_fire\n",
        "    def reset(self): self.fire_map = np.zeros_like(self.grid)\n",
        "\n",
        "# --- The Heavily Upgraded EvacuationEnv for MaskablePPO ---\n",
        "class EvacuationEnv(gym.Env):\n",
        "    def __init__(self, grid, num_agents, fire_start_pos, exits):\n",
        "        super().__init__()\n",
        "        self.grid = grid\n",
        "        self.num_agents = num_agents\n",
        "        self.fire_start_pos = fire_start_pos\n",
        "        self.exits = exits\n",
        "        self.agents = [Person(pos) for pos in self._get_random_agent_starts()]\n",
        "        self.fire_sim = FireSimulator(self.grid)\n",
        "        self.current_step = 0\n",
        "        self.max_steps = 750\n",
        "\n",
        "        # --- KEY CHANGE 1: Fixed-Size Observation Space with Padding ---\n",
        "        obs_fire_shape = config[\"GRID_SIZE\"] * config[\"GRID_SIZE\"]\n",
        "        obs_agent_shape = config[\"MAX_AGENTS\"] * 3  # x, y, state for each agent\n",
        "        total_obs_shape = obs_fire_shape + obs_agent_shape + 1 # +1 for timestep\n",
        "        self.observation_space = spaces.Box(low=0, high=1, shape=(total_obs_shape,), dtype=np.float32)\n",
        "\n",
        "        # --- KEY CHANGE 2: Fixed-Size Action Space for Masking ---\n",
        "        self.action_space = spaces.Discrete(config[\"MAX_EXITS\"])\n",
        "        self._perimeter_coords = self._get_perimeter_coords()\n",
        "\n",
        "    def _get_perimeter_coords(self):\n",
        "        coords = []\n",
        "        s = config[\"GRID_SIZE\"]\n",
        "        for i in range(1, s - 1): coords.append((i, 1)) # Top edge\n",
        "        for i in range(1, s - 1): coords.append((i, s - 2)) # Bottom edge\n",
        "        for i in range(1, s - 1): coords.append((1, i)) # Left edge\n",
        "        for i in range(1, s - 1): coords.append((s - 2, i)) # Right edge\n",
        "        return coords\n",
        "\n",
        "    def _get_random_agent_starts(self):\n",
        "        starts = []\n",
        "        while len(starts) < self.num_agents:\n",
        "            y, x = random.randint(0, self.grid.shape[0]-1), random.randint(0, self.grid.shape[1]-1)\n",
        "            if self.grid[y, x] == 0: starts.append((x, y))\n",
        "        return starts\n",
        "\n",
        "    def _get_observation(self):\n",
        "        fire_obs = self.fire_sim.fire_map.flatten().astype(np.float32)\n",
        "\n",
        "        agent_data = []\n",
        "        state_map = {'CALM': 0.0, 'ALERT': 0.5, 'PANICKED': 1.0}\n",
        "        for i in range(config[\"MAX_AGENTS\"]):\n",
        "            if i < len(self.agents):\n",
        "                agent = self.agents[i]\n",
        "                agent_data.extend([\n",
        "                    agent.pos[0] / self.grid.shape[1],\n",
        "                    agent.pos[1] / self.grid.shape[0],\n",
        "                    state_map[agent.state]\n",
        "                ])\n",
        "            else:\n",
        "                # --- Padding with Zeros ---\n",
        "                agent_data.extend([0.0, 0.0, 0.0])\n",
        "\n",
        "        agent_obs = np.array(agent_data, dtype=np.float32)\n",
        "        time_obs = np.array([self.current_step / self.max_steps], dtype=np.float32)\n",
        "        return np.concatenate([fire_obs, agent_obs, time_obs])\n",
        "\n",
        "    def compute_action_mask(self):\n",
        "        # --- KEY CHANGE 3: The Action Masking Logic ---\n",
        "        mask = np.zeros(config[\"MAX_EXITS\"], dtype=bool)\n",
        "        for exit_pos in self.exits:\n",
        "            # Find the index of this exit in our master list of perimeter coordinates\n",
        "            try:\n",
        "                # Need to handle tuple vs list, ensure pos is (x,y)\n",
        "                exit_pos_tuple = (int(exit_pos[0]), int(exit_pos[1]))\n",
        "                idx = self._perimeter_coords.index(exit_pos_tuple)\n",
        "                mask[idx] = True\n",
        "            except ValueError:\n",
        "                pass # This exit is not on the standard perimeter, ignore\n",
        "        return mask\n",
        "\n",
        "    def reset(self, seed=None):\n",
        "        super().reset(seed=seed)\n",
        "        self.current_step = 0\n",
        "        self.fire_sim.reset()\n",
        "        self.fire_sim.fire_map[self.fire_start_pos[1], self.fire_start_pos[0]] = 1\n",
        "        self.agents = [Person(pos) for pos in self._get_random_agent_starts()]\n",
        "        return self._get_observation(), {}\n",
        "\n",
        "    def step(self, action):\n",
        "        target_exit_coord = self._perimeter_coords[action]\n",
        "        reward = -0.01\n",
        "        self.current_step += 1\n",
        "        self.fire_sim.step()\n",
        "\n",
        "        for agent in self.agents:\n",
        "            if agent.status == 'evacuating':\n",
        "                agent.update_state(self.fire_sim.fire_map)\n",
        "                if not agent.path or self.current_step % 10 == 0:\n",
        "                    agent.compute_path(self.grid, target_exit_coord, self.fire_sim.fire_map)\n",
        "                agent.move()\n",
        "                agent.check_status(self.fire_sim.fire_map, self.exits)\n",
        "                if agent.status == 'escaped': reward += 10\n",
        "                elif agent.status == 'burned': reward -= 10\n",
        "\n",
        "        terminated = all(agent.status != 'evacuating' for agent in self.agents)\n",
        "        truncated = self.current_step >= self.max_steps\n",
        "        return self._get_observation(), reward, terminated, truncated, {}\n",
        "\n",
        "    # Required for MaskablePPO\n",
        "    def valid_action_mask(self):\n",
        "        return self.compute_action_mask()\n",
        "\n",
        "print(\"--- Upgraded Simulation Classes Defined ---\")\n",
        "print(\"EvacuationEnv is now ready for Action Masking and Padded Observations.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CTxzdZAE4WUt"
      },
      "source": [
        "# Cell 5: The Dynamic Training Environment (The \"Gymnasium Factory\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lc8pu601Kcjs",
        "outputId": "9c231f75-07f1-478f-f195-261a1910acb1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Dynamic Training Environment Factory Defined ---\n",
            "Ready to create randomized training scenarios.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "from sb3_contrib.common.wrappers import ActionMasker\n",
        "\n",
        "class RandomFloorplanEnv(gym.Env):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        print(\"Loading Hugging Face dataset... (this may take a moment)\")\n",
        "        self.dataset = load_dataset(config[\"DATASET_NAME\"], split='train')\n",
        "        print(\"Dataset loaded.\")\n",
        "\n",
        "        # The underlying env will change every reset, so we define a \"master\" space\n",
        "        self.observation_space = spaces.Box(\n",
        "            low=0, high=1,\n",
        "            shape=((config[\"GRID_SIZE\"]**2) + (config[\"MAX_AGENTS\"] * 3) + 1,),\n",
        "            dtype=np.float32\n",
        "        )\n",
        "        self.action_space = spaces.Discrete(config[\"MAX_EXITS\"])\n",
        "\n",
        "        self.current_env = None\n",
        "\n",
        "    def _create_new_episode_env(self):\n",
        "        \"\"\"The core logic for creating a new, randomized scenario.\"\"\"\n",
        "        # --- 1. Get a random floor plan and create the grid ---\n",
        "        random_idx = random.randint(0, len(self.dataset) - 1)\n",
        "        plan_image = self.dataset[random_idx]['plans'].convert(\"RGB\")\n",
        "        grid = create_grid_from_image(unet_model, plan_image)\n",
        "\n",
        "        # --- 2. Find exits on this specific grid ---\n",
        "        # We find exits by looking for openings on the perimeter\n",
        "        exits = []\n",
        "        s = config[\"GRID_SIZE\"]\n",
        "        for x in range(1, s - 1):\n",
        "            if grid[1, x] == 0: exits.append((x, 1))\n",
        "            if grid[s-2, x] == 0: exits.append((x, s-2))\n",
        "        for y in range(1, s - 1):\n",
        "            if grid[y, 1] == 0: exits.append((1, y))\n",
        "            if grid[y, s-2] == 0: exits.append((s-2, y))\n",
        "\n",
        "        # Skip this floor plan if it has no detectable exits\n",
        "        if not exits:\n",
        "            return self._create_new_episode_env() # Recursively try again\n",
        "\n",
        "        # --- 3. Randomize the scenario ---\n",
        "        num_agents = random.randint(3, config[\"MAX_AGENTS\"])\n",
        "\n",
        "        # Find a valid, non-wall spot for the fire to start\n",
        "        valid_starts = np.argwhere(grid == 0)\n",
        "        if len(valid_starts) == 0:\n",
        "             return self._create_new_episode_env() # Try again if no valid spots\n",
        "\n",
        "        fire_start_pos_yx = random.choice(valid_starts)\n",
        "        fire_start_pos_xy = (fire_start_pos_yx[1], fire_start_pos_yx[0]) # Convert to (x,y)\n",
        "\n",
        "        # --- 4. Create and return the configured environment ---\n",
        "        return EvacuationEnv(\n",
        "            grid=grid,\n",
        "            num_agents=num_agents,\n",
        "            fire_start_pos=fire_start_pos_xy,\n",
        "            exits=exits\n",
        "        )\n",
        "\n",
        "    def reset(self, seed=None):\n",
        "        if seed is not None:\n",
        "            super().reset(seed=seed)\n",
        "\n",
        "        self.current_env = self._create_new_episode_env()\n",
        "        return self.current_env.reset()\n",
        "\n",
        "    def step(self, action):\n",
        "        return self.current_env.step(action)\n",
        "\n",
        "    # This is the function the ActionMasker will call\n",
        "    def get_action_mask(self):\n",
        "        return self.current_env.compute_action_mask()\n",
        "\n",
        "# --- Helper function to create the final, wrapped training environment ---\n",
        "def make_training_env():\n",
        "    \"\"\"Creates an instance of our dynamic env and wraps it with the ActionMasker.\"\"\"\n",
        "    env = RandomFloorplanEnv()\n",
        "    masked_env = ActionMasker(env, action_mask_fn=lambda e: e.get_action_mask())\n",
        "    return masked_env\n",
        "\n",
        "print(\"\\n--- Dynamic Training Environment Factory Defined ---\")\n",
        "print(\"Ready to create randomized training scenarios.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w5KEtKRi4YuB"
      },
      "source": [
        "# Cell 6: The Final, Definitive Training Script for the V2.0 AI Commander\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ALj-5VJFKc47",
        "outputId": "75a9160e-cc15-4411-8e3b-6626b4f1ae43"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Initializing Parallel Training Environments ---\n"
          ]
        }
      ],
      "source": [
        "# Cell 6 (CORRECTED): The Final, Definitive Training Script for the V2.0 AI Commander\n",
        "\n",
        "# MODIFIED: Added CheckpointCallback to the imports\n",
        "from stable_baselines3.common.callbacks import CheckpointCallback\n",
        "\n",
        "# --- 1. Create the Parallel, Masked, Dynamic Training Environments ---\n",
        "print(\"--- Initializing Parallel Training Environments ---\")\n",
        "vec_env = make_vec_env(\n",
        "    make_training_env,\n",
        "    n_envs=config[\"N_ENVS\"],\n",
        "    vec_env_cls=SubprocVecEnv\n",
        ")\n",
        "print(f\"--- {config['N_ENVS']} parallel environments created successfully ---\")\n",
        "\n",
        "# --- 2. Define PPO Hyperparameters and Model Path ---\n",
        "PPO_MODEL_PATH = config[\"PPO_MODEL_PATH\"]\n",
        "hyperparams = {\n",
        "    \"learning_rate\": 3e-4, \"n_steps\": 2048, \"batch_size\": 256, \"n_epochs\": 10,\n",
        "    \"gamma\": 0.99, \"gae_lambda\": 0.95, \"clip_range\": 0.2, \"ent_coef\": 0.01,\n",
        "    \"vf_coef\": 0.5, \"max_grad_norm\": 0.5,\n",
        "    \"policy_kwargs\": dict(net_arch=dict(pi=[256, 256], vf=[256, 256])),\n",
        "    \"verbose\": 1, \"device\": 'cuda', \"tensorboard_log\": \"./ppo_v2_tensorboard/\"\n",
        "}\n",
        "\n",
        "# --- 3. Setup Checkpoint Callback to Save Progress ---\n",
        "checkpoint_callback = CheckpointCallback(\n",
        "    save_freq=max(10000 // config[\"N_ENVS\"], 1), # Save every ~10k total steps\n",
        "    save_path='./checkpoints/',\n",
        "    name_prefix='ppo_commander_v2'\n",
        ")\n",
        "\n",
        "# --- 4. Load or Create the MaskablePPO Model ---\n",
        "if os.path.exists(PPO_MODEL_PATH):\n",
        "    print(\"--- Found existing V2.0 model! Loading to continue training... ---\")\n",
        "    model = MaskablePPO.load(PPO_MODEL_PATH, env=vec_env, device='cuda')\n",
        "else:\n",
        "    print(\"--- No existing V2.0 model found. Creating a new one... ---\")\n",
        "    model = MaskablePPO(\"MlpPolicy\", vec_env, **hyperparams)\n",
        "\n",
        "# --- 5. THE FINAL TRAINING RUN ---\n",
        "print(f\"\\n--- Starting Final AI Commander Training for {config['TOTAL_TIMESTEPS']} timesteps ---\")\n",
        "print(\"The AI will now train on a dynamic curriculum of randomized floor plans and scenarios.\")\n",
        "\n",
        "try:\n",
        "    model.learn(\n",
        "        total_timesteps=config[\"TOTAL_TIMESTEPS\"],\n",
        "        progress_bar=True,\n",
        "        reset_num_timesteps=False,\n",
        "        callback=checkpoint_callback\n",
        "    )\n",
        "\n",
        "    print(f\"\\n--- {config['TOTAL_TIMESTEPS']} timesteps of training complete ---\")\n",
        "    model.save(PPO_MODEL_PATH)\n",
        "    print(f\"\\nFinal AI Commander model saved to {PPO_MODEL_PATH}\")\n",
        "\n",
        "except KeyboardInterrupt:\n",
        "    # --- Graceful exit on interruption ---\n",
        "    model.save(PPO_MODEL_PATH)\n",
        "    print(\"\\n--- Training Interrupted by User ---\")\n",
        "    print(f\"Current progress has been saved to {PPO_MODEL_PATH}\")\n",
        "\n",
        "finally:\n",
        "    # --- Clean up the environments ---\n",
        "    vec_env.close()\n",
        "    print(\"\\n--- Training environments closed ---\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
